AWSTemplateFormatVersion: '2010-09-09'
Description: 'CloudFormation template for Parkinson fMRI detection using SageMaker Notebook Instance with GitHub integration'

Parameters:
  NotebookInstanceName:
    Type: String
    Default: 'parkinson-fmri-detector'
    Description: 'Name for the SageMaker notebook instance'
    
  InstanceType:
    Type: String
    Default: 'ml.t3.medium'
    AllowedValues:
      - ml.t3.medium
      - ml.t3.large
      - ml.t3.xlarge
      - ml.m5.large
      - ml.m5.xlarge
      - ml.m5.2xlarge
    Description: 'SageMaker notebook instance type'
    
  BucketName:
    Type: String
    Default: 'fmri-dataset-bucket'
    Description: 'Name for the S3 bucket to store fMRI datasets (must be globally unique)'
    
  GitHubRepository:
    Type: String
    Default: 'https://github.com/vanyaphi/Parkinson-fMRI-detector.git'
    Description: 'GitHub repository URL to clone into the notebook instance'
    
  VolumeSize:
    Type: Number
    Default: 20
    MinValue: 5
    MaxValue: 16384
    Description: 'Size of the EBS volume in GB for the notebook instance'

Resources:
  # S3 Bucket for fMRI datasets
  FMRIDatasetBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${BucketName}-${AWS::AccountId}-${AWS::Region}'
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      VersioningConfiguration:
        Status: Enabled
      LifecycleConfiguration:
        Rules:
          - Id: DeleteIncompleteMultipartUploads
            Status: Enabled
            AbortIncompleteMultipartUpload:
              DaysAfterInitiation: 7
          - Id: TransitionToIA
            Status: Enabled
            Transitions:
              - TransitionInDays: 30
                StorageClass: STANDARD_IA
              - TransitionInDays: 90
                StorageClass: GLACIER
      Tags:
        - Key: Purpose
          Value: 'fMRI Dataset Storage'
        - Key: Project
          Value: 'Parkinson Detection'

  # S3 Bucket Policy for secure access
  FMRIDatasetBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref FMRIDatasetBucket
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Sid: DenyInsecureConnections
            Effect: Deny
            Principal: '*'
            Action: 's3:*'
            Resource:
              - !Sub 'arn:aws:s3:::${FMRIDatasetBucket}/*'
              - !GetAtt FMRIDatasetBucket.Arn
            Condition:
              Bool:
                'aws:SecureTransport': 'false'
          - Sid: AllowSageMakerAccess
            Effect: Allow
            Principal:
              AWS: !GetAtt SageMakerNotebookRole.Arn
            Action:
              - 's3:GetObject'
              - 's3:PutObject'
              - 's3:DeleteObject'
              - 's3:ListBucket'
              - 's3:GetBucketLocation'
            Resource:
              - !Sub 'arn:aws:s3:::${FMRIDatasetBucket}/*'
              - !GetAtt FMRIDatasetBucket.Arn

  # IAM Role for SageMaker Notebook Instance
  SageMakerNotebookRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - sagemaker.amazonaws.com
            Action:
              - sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSageMakerFullAccess
      Policies:
        - PolicyName: S3AccessPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:DeleteObject
                  - s3:ListBucket
                  - s3:GetBucketLocation
                  - s3:GetBucketVersioning
                Resource:
                  - !Sub 'arn:aws:s3:::${FMRIDatasetBucket}/*'
                  - !GetAtt FMRIDatasetBucket.Arn
              - Effect: Allow
                Action:
                  - s3:ListAllMyBuckets
                  - s3:GetBucketLocation
                Resource: '*'
        - PolicyName: CloudWatchLogsPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                  - logs:DescribeLogStreams
                  - logs:DescribeLogGroups
                Resource: !Sub 'arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*'

  # Lifecycle Configuration for auto-shutdown and setup
  NotebookLifecycleConfig:
    Type: AWS::SageMaker::NotebookInstanceLifecycleConfig
    Properties:
      NotebookInstanceLifecycleConfigName: 'fmrinblc'
      OnCreate:
        - Content: !Base64 |
            #!/bin/bash
            set -e
            
            # Update system packages
            sudo yum update -y
            
            # Install additional Python packages for fMRI analysis
            sudo -u ec2-user -i <<'EOF'
            source activate python3
            
            # Install neuroimaging packages
            pip install --upgrade pip
            pip install nilearn nibabel
            pip install scikit-learn tensorflow pandas numpy matplotlib seaborn
            pip install plotly imbalanced-learn
            pip install xgboost lightgbm optuna
            pip install boto3 sagemaker
            pip install scipy statsmodels
            
            echo "Package installation completed"
            EOF
            
            # Create auto-shutdown script
            cat > /home/ec2-user/SageMaker/auto-shutdown.py << 'SCRIPT'
            #!/usr/bin/env python3
            import boto3
            import os
            import time
            import subprocess
            from datetime import datetime
            
            IDLE_TIME_MINUTES = 30
            CHECK_INTERVAL_SECONDS = 300
            
            def is_notebook_idle():
                try:
                    result = subprocess.run(['pgrep', '-f', 'ipykernel'], 
                                          capture_output=True, text=True)
                    if result.returncode == 0:
                        return False
                    
                    sagemaker_dir = '/home/ec2-user/SageMaker'
                    cutoff_time = time.time() - (IDLE_TIME_MINUTES * 60)
                    
                    for root, dirs, files in os.walk(sagemaker_dir):
                        for file in files:
                            if file.endswith(('.ipynb', '.py')):
                                file_path = os.path.join(root, file)
                                if os.path.getmtime(file_path) > cutoff_time:
                                    return False
                    return True
                except:
                    return False
            
            def shutdown_instance():
                try:
                    import urllib.request
                    token = urllib.request.urlopen('http://169.254.169.254/latest/api/token', 
                                                 urllib.request.Request('http://169.254.169.254/latest/api/token', 
                                                                      headers={'X-aws-ec2-metadata-token-ttl-seconds': '21600'}, 
                                                                      method='PUT')).read().decode()
                    
                    region = urllib.request.urlopen('http://169.254.169.254/latest/meta-data/placement/region',
                                                  urllib.request.Request('http://169.254.169.254/latest/meta-data/placement/region',
                                                                       headers={'X-aws-ec2-metadata-token': token})).read().decode()
                    
                    client = boto3.client('sagemaker', region_name=region)
                    
                    # Get notebook name from environment or use default
                    notebook_name = os.environ.get('NOTEBOOK_INSTANCE_NAME', 'parkinson-fmri-detector')
                    
                    client.stop_notebook_instance(NotebookInstanceName=notebook_name)
                    print(f"Shutdown initiated for {notebook_name}")
                except Exception as e:
                    print(f"Error during shutdown: {e}")
            
            def main():
                idle_start_time = None
                while True:
                    if is_notebook_idle():
                        if idle_start_time is None:
                            idle_start_time = time.time()
                            print(f"Idle period started at {datetime.now()}")
                        elif time.time() - idle_start_time > (IDLE_TIME_MINUTES * 60):
                            print(f"Instance idle for {IDLE_TIME_MINUTES} minutes. Shutting down...")
                            shutdown_instance()
                            break
                    else:
                        if idle_start_time is not None:
                            print(f"Activity resumed at {datetime.now()}")
                        idle_start_time = None
                    time.sleep(CHECK_INTERVAL_SECONDS)
            
            if __name__ == "__main__":
                main()
            SCRIPT
            
            chmod +x /home/ec2-user/SageMaker/auto-shutdown.py
            
            # Create systemd service
            cat > /etc/systemd/system/sagemaker-auto-shutdown.service << 'SERVICE'
            [Unit]
            Description=SageMaker Notebook Auto-shutdown
            After=network.target
            
            [Service]
            Type=simple
            User=ec2-user
            WorkingDirectory=/home/ec2-user/SageMaker
            ExecStart=/usr/bin/python3 /home/ec2-user/SageMaker/auto-shutdown.py
            Environment=NOTEBOOK_INSTANCE_NAME=parkinson-fmri-detector
            Restart=always
            RestartSec=60
            
            [Install]
            WantedBy=multi-user.target
            SERVICE
            
            systemctl daemon-reload
            systemctl enable sagemaker-auto-shutdown.service
            systemctl start sagemaker-auto-shutdown.service
            
      OnStart:
        - Content: !Base64 |
            #!/bin/bash
            set -e
            systemctl restart sagemaker-auto-shutdown.service
            sudo -u ec2-user -i <<'EOF'
            echo "export AWS_DEFAULT_REGION=$(curl -s http://169.254.169.254/latest/meta-data/placement/region)" >> ~/.bashrc
            EOF

  # SageMaker Notebook Instance
  SageMakerNotebookInstance:
    Type: AWS::SageMaker::NotebookInstance
    Properties:
      NotebookInstanceName: !Ref NotebookInstanceName
      InstanceType: !Ref InstanceType
      RoleArn: !GetAtt SageMakerNotebookRole.Arn
      VolumeSizeInGB: !Ref VolumeSize
      DefaultCodeRepository: !Ref GitHubRepository
      LifecycleConfigName: !GetAtt NotebookLifecycleConfig.NotebookInstanceLifecycleConfigName
      Tags:
        - Key: Purpose
          Value: 'Parkinson fMRI Detection'
        - Key: Project
          Value: 'Neuroimaging Research'
        - Key: AutoShutdown
          Value: 'Enabled'

  # Lambda function for S3 setup
  S3SetupFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${NotebookInstanceName}-s3-setup'
      Runtime: python3.9
      Handler: index.lambda_handler
      Role: !GetAtt S3SetupRole.Arn
      Timeout: 60
      Code:
        ZipFile: |
          import boto3
          import json
          import cfnresponse
          
          def lambda_handler(event, context):
              try:
                  if event['RequestType'] == 'Create':
                      s3_client = boto3.client('s3')
                      bucket_name = event['ResourceProperties']['BucketName']
                      
                      files = [
                          ('datasets/controls/README.txt', 'Upload control subject fMRI data here'),
                          ('datasets/patients/README.txt', 'Upload patient fMRI data here'),
                          ('results/README.txt', 'Analysis results will be saved here'),
                          ('models/README.txt', 'Trained models will be saved here')
                      ]
                      
                      for key, body in files:
                          s3_client.put_object(Bucket=bucket_name, Key=key, Body=body)
                      
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
                  else:
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
              except Exception as e:
                  print(f"Error: {str(e)}")
                  cfnresponse.send(event, context, cfnresponse.FAILED, {})

  # IAM Role for Lambda
  S3SetupRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: S3Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:PutObject
                Resource: !Sub 'arn:aws:s3:::${FMRIDatasetBucket}/*'

  # Custom resource for S3 setup
  S3Setup:
    Type: AWS::CloudFormation::CustomResource
    Properties:
      ServiceToken: !GetAtt S3SetupFunction.Arn
      BucketName: !Ref FMRIDatasetBucket

Outputs:
  NotebookInstanceName:
    Description: 'SageMaker Notebook Instance Name'
    Value: !Ref SageMakerNotebookInstance
    Export:
      Name: !Sub '${AWS::StackName}-NotebookInstance'

  NotebookInstanceUrl:
    Description: 'SageMaker Notebook Instance URL'
    Value: !Sub 'https://${SageMakerNotebookInstance}.notebook.${AWS::Region}.sagemaker.aws/tree'
    Export:
      Name: !Sub '${AWS::StackName}-NotebookUrl'

  S3BucketName:
    Description: 'S3 Bucket for fMRI datasets'
    Value: !Ref FMRIDatasetBucket
    Export:
      Name: !Sub '${AWS::StackName}-S3Bucket'

  ExecutionRoleArn:
    Description: 'SageMaker Execution Role ARN'
    Value: !GetAtt SageMakerNotebookRole.Arn
    Export:
      Name: !Sub '${AWS::StackName}-ExecutionRole'

  GitHubRepository:
    Description: 'GitHub repository cloned to notebook'
    Value: !Ref GitHubRepository
    Export:
      Name: !Sub '${AWS::StackName}-GitHubRepo'